{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f6c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import datasets\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b048ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2 = datasets.load_dataset(\"/root/group-shared/jrc/data/sst2\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95dbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"In this task, you are given sentences from movie reviews. The task is to classify a sentence as \\\"positive\\\" if the sentiment of the sentence is positive or as \\\"negative\\\" if the sentiment of the sentence is negative.\"\n",
    "system_prompt = \"\"\n",
    "generate_model_ip = \"127.0.0.1\"\n",
    "generate_model_port = 33337\n",
    "generate_model_config = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_new_tokens\": 1,\n",
    "    \"custom_params\": {\"token_id_list\": [30487, 42224]}\n",
    "}\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/group-shared/jrc/base_models/Qwen3-32B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f11e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from sglang.srt.sampling.custom_logit_processor import CustomLogitProcessor\n",
    "\n",
    "class DeterministicLogitProcessor(CustomLogitProcessor):\n",
    "    \"\"\"A dummy logit processor that changes the logits to always\n",
    "    sample the given token id.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, logits, custom_param_list):\n",
    "        # Check that the number of logits matches the number of custom parameters\n",
    "        assert logits.shape[0] == len(custom_param_list)\n",
    "        key = \"token_id_list\"\n",
    "\n",
    "        for i, param_dict in enumerate(custom_param_list):\n",
    "            # Mask all other tokens\n",
    "            temp_logits = logits[i, :].clone()\n",
    "            logits[i, :] = -float(\"inf\")\n",
    "            logits[i, param_dict[key]] = temp_logits[param_dict[key]]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4201e05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goes to absurd lengths \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "example = sst2[\"train\"][10]\n",
    "print(example[\"sentence\"])\n",
    "print(example[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7464fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": f\"{instruction}\\nText: {example['sentence']}\"}], \n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False\n",
    ")\n",
    "response = requests.post(\n",
    "    f\"http://{generate_model_ip}:{generate_model_port}/generate\",\n",
    "    json={\n",
    "        \"text\": prompt,\n",
    "        \"sampling_params\": generate_model_config,\n",
    "        \"custom_logit_processor\": DeterministicLogitProcessor().to_str(),\n",
    "    },\n",
    ")\n",
    "completion = response.json()[\"text\"]\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79d12a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306]\n",
      "[8222]\n",
      "[59568]\n",
      "[1921]\n"
     ]
    }
   ],
   "source": [
    "x = tokenizer.encode(\"ent\")\n",
    "print(x)\n",
    "x = tokenizer.encode(\"contr\")\n",
    "print(x)\n",
    "x = tokenizer.encode(\"neutral\")\n",
    "print(x)\n",
    "x = tokenizer.encode(\"not\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3210a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRewrite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
